#!/usr/bin/env python3
"""
å®éªŒ#1: ä¸€æ­¥æ‰©æ•£ Energy-Head æ¢ç´¢
åŠ¨æœº: èƒ½é‡-æ‰©æ•£åŒæ„ï¼Œç”¨å•æ­¥Energyæ›¿ä»£æ•´ä¸ªVAR+VAE pipeline
ç›®æ ‡: Teacher(DiT) â†’ Student(Energy) è’¸é¦ï¼Œloss < 0.05
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import json
import time
from pathlib import Path
from tqdm import tqdm
import argparse
import matplotlib.pyplot as plt

class TeacherDiT(nn.Module):
    """ç®€åŒ–çš„DiT Teacheræ¨¡å‹"""
    
    def __init__(self, dim=768, num_heads=12, num_layers=6):
        super().__init__()
        self.dim = dim
        
        # ç®€åŒ–çš„DiTæ¶æ„
        self.patch_embed = nn.Conv2d(3, dim, 16, stride=16)  # 256â†’16
        self.pos_embed = nn.Parameter(torch.randn(1, 256, dim))
        
        # Transformer layers
        self.layers = nn.ModuleList([
            nn.TransformerEncoderLayer(
                d_model=dim, 
                nhead=num_heads, 
                dim_feedforward=dim*4,
                batch_first=True
            ) for _ in range(num_layers)
        ])
        
        # Noise prediction head
        self.noise_head = nn.Sequential(
            nn.LayerNorm(dim),
            nn.Linear(dim, dim),
            nn.SiLU(),
            nn.Linear(dim, 3 * 16 * 16),  # é¢„æµ‹å™ªå£°patch
        )
        
        print(f"ğŸ“ Teacher DiT initialized: {sum(p.numel() for p in self.parameters())/1e6:.1f}M params")
    
    def forward(self, x, timestep=None):
        """å‰å‘ä¼ æ’­ - é¢„æµ‹å™ªå£°"""
        B, C, H, W = x.shape
        
        # Patch embedding
        x = self.patch_embed(x)  # [B, dim, 16, 16]
        x = x.flatten(2).transpose(1, 2)  # [B, 256, dim]
        x = x + self.pos_embed
        
        # Transformer
        for layer in self.layers:
            x = layer(x)
        
        # é¢„æµ‹å™ªå£°
        noise_pred = self.noise_head(x.mean(1))  # Global pooling
        noise_pred = noise_pred.view(B, 3, 16, 16)
        
        # ä¸Šé‡‡æ ·åˆ°åŸå°ºå¯¸
        noise_pred = F.interpolate(noise_pred, size=(H, W), mode='bilinear')
        
        return noise_pred

class OneStepEnergyHead(nn.Module):
    """ä¸€æ­¥Energy Head - è½»é‡çº§å­¦ç”Ÿæ¨¡å‹"""
    
    def __init__(self, dim=256, n_layers=4):
        super().__init__()
        self.dim = dim
        
        # è¾“å…¥æŠ•å½±
        self.input_proj = nn.Conv2d(3, dim, 8, stride=8)  # 256â†’32
        
        # Energy processing layers
        self.energy_layers = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(dim, dim, 3, padding=1),
                nn.GroupNorm(8, dim),
                nn.SiLU(),
                nn.Conv2d(dim, dim, 3, padding=1),
            ) for _ in range(n_layers)
        ])
        
        # è¾“å‡ºæŠ•å½± - é¢„æµ‹å™ªå£°
        self.noise_head = nn.Sequential(
            nn.Conv2d(dim, 128, 3, padding=1),
            nn.SiLU(),
            nn.Conv2d(128, 3, 3, padding=1)
        )
        
        params = sum(p.numel() for p in self.parameters()) / 1e6
        print(f"âš¡ OneStep Energy Head: {params:.1f}M params")
    
    def forward(self, x):
        """å•æ­¥é¢„æµ‹å™ªå£°"""
        B, C, H, W = x.shape
        
        # è¾“å…¥æŠ•å½±
        h = self.input_proj(x)  # [B, dim, 32, 32]
        
        # Energy processing with residual connections
        for layer in self.energy_layers:
            residual = h
            h = layer(h) + residual
        
        # é¢„æµ‹å™ªå£°
        noise_pred = self.noise_head(h)  # [B, 3, 32, 32]
        
        # ä¸Šé‡‡æ ·åˆ°åŸå°ºå¯¸
        noise_pred = F.interpolate(noise_pred, size=(H, W), mode='bilinear')
        
        return noise_pred

class DiffusionDataSimulator:
    """æ‰©æ•£è¿‡ç¨‹æ•°æ®æ¨¡æ‹Ÿå™¨"""
    
    def __init__(self, num_timesteps=1000, beta_start=0.0001, beta_end=0.02):
        self.num_timesteps = num_timesteps
        
        # çº¿æ€§noise schedule
        self.betas = torch.linspace(beta_start, beta_end, num_timesteps)
        self.alphas = 1.0 - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)
    
    def add_noise(self, x0, noise, timesteps):
        """æ·»åŠ å™ªå£°åˆ°åŸå›¾"""
        alphas_cumprod_t = self.alphas_cumprod[timesteps]
        sqrt_alphas_cumprod_t = torch.sqrt(alphas_cumprod_t).view(-1, 1, 1, 1)
        sqrt_one_minus_alphas_cumprod_t = torch.sqrt(1 - alphas_cumprod_t).view(-1, 1, 1, 1)
        
        noisy_x = sqrt_alphas_cumprod_t * x0 + sqrt_one_minus_alphas_cumprod_t * noise
        return noisy_x
    
    def sample_timesteps(self, batch_size, device):
        """éšæœºé‡‡æ ·æ—¶é—´æ­¥"""
        return torch.randint(0, self.num_timesteps, (batch_size,), device=device)

def distillation_loss(pred_noise, target_noise, loss_type='mse'):
    """è’¸é¦æŸå¤±å‡½æ•°"""
    if loss_type == 'mse':
        return F.mse_loss(pred_noise, target_noise)
    elif loss_type == 'l1':
        return F.l1_loss(pred_noise, target_noise)
    elif loss_type == 'huber':
        return F.huber_loss(pred_noise, target_noise)
    else:
        raise ValueError(f"Unknown loss type: {loss_type}")

def run_experiment_1(args):
    """å®éªŒ#1ä¸»å‡½æ•°"""
    
    print("ğŸš€ å®éªŒ#1: ä¸€æ­¥æ‰©æ•£ Energy-Head æ¢ç´¢")
    print("ğŸ¯ ç›®æ ‡: ç”¨å•æ­¥Energyæ›¿ä»£æ•´ä¸ªVAR+VAE pipeline")
    print("=" * 60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”§ Device: {device}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # 1. åˆå§‹åŒ–æ¨¡å‹
    print("\nğŸ“¦ Initializing models...")
    teacher = TeacherDiT().to(device)
    student = OneStepEnergyHead().to(device)
    diffusion_simulator = DiffusionDataSimulator()
    
    if device.type == 'cuda':
        teacher = teacher.half()
        student = student.half()
    
    print("âœ… Models initialized")
    
    # 2. é¢„è®­ç»ƒTeacher (ç®€åŒ–ç‰ˆæœ¬)
    print("\nğŸ“ Pre-training Teacher DiT...")
    teacher_optimizer = torch.optim.AdamW(teacher.parameters(), lr=1e-4)
    
    # ç®€å•çš„è‡ªè®­ç»ƒå¾ªç¯
    teacher.train()
    for step in tqdm(range(args.teacher_steps), desc="Teacher pre-training"):
        # ç”Ÿæˆéšæœº"å›¾ç‰‡"
        fake_images = torch.randn(args.batch_size, 3, 256, 256, device=device)
        if device.type == 'cuda':
            fake_images = fake_images.half()
        
        # æ·»åŠ å™ªå£°
        noise = torch.randn_like(fake_images)
        timesteps = diffusion_simulator.sample_timesteps(args.batch_size, device)
        noisy_images = diffusion_simulator.add_noise(fake_images, noise, timesteps)
        
        # Teacheré¢„æµ‹å™ªå£°
        pred_noise = teacher(noisy_images)
        
        # è‡ªä¸€è‡´æ€§æŸå¤±
        loss = F.mse_loss(pred_noise, noise)
        
        teacher_optimizer.zero_grad()
        loss.backward()
        teacher_optimizer.step()
        
        if step % 100 == 0:
            print(f"   Teacher step {step}: loss = {loss.item():.4f}")
    
    teacher.eval()
    print("âœ… Teacher pre-training completed")
    
    # 3. å­¦ç”Ÿæ¨¡å‹è’¸é¦
    print(f"\nâš¡ Student distillation for {args.distill_steps} steps...")
    student_optimizer = torch.optim.AdamW(student.parameters(), lr=args.learning_rate)
    
    # è®°å½•è®­ç»ƒè¿‡ç¨‹
    train_losses = []
    best_loss = float('inf')
    convergence_threshold = 0.05
    
    student.train()
    for step in tqdm(range(args.distill_steps), desc="Student distillation"):
        # ç”Ÿæˆè®­ç»ƒæ•°æ®
        fake_images = torch.randn(args.batch_size, 3, 256, 256, device=device)
        if device.type == 'cuda':
            fake_images = fake_images.half()
        
        noise = torch.randn_like(fake_images)
        timesteps = diffusion_simulator.sample_timesteps(args.batch_size, device)
        noisy_images = diffusion_simulator.add_noise(fake_images, noise, timesteps)
        
        # Teacheré¢„æµ‹ï¼ˆfrozenï¼‰
        with torch.no_grad():
            teacher_pred = teacher(noisy_images)
        
        # Studenté¢„æµ‹
        student_pred = student(noisy_images)
        
        # è’¸é¦æŸå¤±
        loss = distillation_loss(student_pred, teacher_pred, args.loss_type)
        
        # åå‘ä¼ æ’­
        student_optimizer.zero_grad()
        loss.backward()
        student_optimizer.step()
        
        # è®°å½•
        train_losses.append(loss.item())
        
        if loss.item() < best_loss:
            best_loss = loss.item()
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            torch.save(student.state_dict(), output_dir / 'best_student.pth')
        
        # å®šæœŸè¾“å‡º
        if step % 100 == 0:
            avg_loss = sum(train_losses[-100:]) / min(100, len(train_losses))
            print(f"   Step {step}: loss = {loss.item():.4f}, avg_100 = {avg_loss:.4f}")
            
            # æ£€æŸ¥æ”¶æ•›
            if avg_loss < convergence_threshold:
                print(f"ğŸ‰ Convergence achieved! avg_loss = {avg_loss:.4f} < {convergence_threshold}")
                break
    
    student.eval()
    
    # 4. æ€§èƒ½è¯„ä¼°
    print("\nğŸ“Š Performance evaluation...")
    
    # å•æ­¥ç”Ÿæˆæµ‹è¯•
    test_images = torch.randn(args.batch_size, 3, 256, 256, device=device)
    if device.type == 'cuda':
        test_images = test_images.half()
    
    # Teacher vs Studentå¯¹æ¯”
    with torch.no_grad():
        # æ—¶é—´æµ‹è¯•
        teacher_times = []
        student_times = []
        
        for _ in range(10):
            # Teacher timing
            if device.type == 'cuda':
                torch.cuda.synchronize()
            start = time.time()
            teacher_output = teacher(test_images)
            if device.type == 'cuda':
                torch.cuda.synchronize()
            teacher_times.append((time.time() - start) * 1000)
            
            # Student timing
            if device.type == 'cuda':
                torch.cuda.synchronize()
            start = time.time()
            student_output = student(test_images)
            if device.type == 'cuda':
                torch.cuda.synchronize()
            student_times.append((time.time() - start) * 1000)
        
        teacher_latency = sum(teacher_times) / len(teacher_times) / args.batch_size
        student_latency = sum(student_times) / len(student_times) / args.batch_size
        speedup = teacher_latency / student_latency
        
        # é¢„æµ‹è´¨é‡å¯¹æ¯”
        prediction_diff = F.mse_loss(student_output, teacher_output).item()
    
    # 5. ç»“æœåˆ†æ
    final_loss = sum(train_losses[-100:]) / min(100, len(train_losses))
    convergence_achieved = final_loss < convergence_threshold
    
    results = {
        'experiment': 'one_step_energy_distillation',
        'timestamp': time.strftime('%Y%m%d_%H%M%S'),
        'config': {
            'teacher_steps': args.teacher_steps,
            'distill_steps': args.distill_steps,
            'batch_size': args.batch_size,
            'learning_rate': args.learning_rate,
            'loss_type': args.loss_type
        },
        'training': {
            'final_loss': final_loss,
            'best_loss': best_loss,
            'convergence_threshold': convergence_threshold,
            'convergence_achieved': convergence_achieved,
            'total_steps': len(train_losses)
        },
        'performance': {
            'teacher_latency_ms_per_image': teacher_latency,
            'student_latency_ms_per_image': student_latency,
            'speedup': speedup,
            'prediction_mse': prediction_diff
        },
        'model_sizes': {
            'teacher_params_m': sum(p.numel() for p in teacher.parameters()) / 1e6,
            'student_params_m': sum(p.numel() for p in student.parameters()) / 1e6
        }
    }
    
    # å®éªŒè¯„ä¼°
    if convergence_achieved:
        if speedup > 2.0 and prediction_diff < 0.1:
            status = "BREAKTHROUGH"
            print("ğŸ† å®éªŒ#1 é‡å¤§çªç ´ï¼ä¸€æ­¥Energy Headè’¸é¦æˆåŠŸ")
        else:
            status = "SUCCESS"
            print("ğŸŸ¢ å®éªŒ#1 æˆåŠŸï¼è¾¾åˆ°æ”¶æ•›æ¡ä»¶")
    elif final_loss < 0.1:
        status = "PROMISING"
        print("ğŸŸ¡ å®éªŒ#1 æœ‰å¸Œæœ›ï¼Œæ¥è¿‘æ”¶æ•›")
    else:
        status = "NEEDS_WORK"
        print("ğŸ”´ å®éªŒ#1 éœ€è¦è°ƒè¯•ï¼Œæœªè¾¾åˆ°é¢„æœŸ")
    
    results['status'] = status
    
    print(f"\nğŸ¯ å®éªŒ#1 ç»“æœæ€»ç»“:")
    print(f"  æœ€ç»ˆæŸå¤±: {final_loss:.4f}")
    print(f"  æ”¶æ•›è¾¾æˆ: {'âœ…' if convergence_achieved else 'âŒ'}")
    print(f"  åŠ é€Ÿæ¯”: {speedup:.1f}x")
    print(f"  é¢„æµ‹å·®å¼‚: {prediction_diff:.4f}")
    print(f"  çŠ¶æ€: {status}")
    
    # 6. ä¿å­˜ç»“æœå’Œæ¨¡å‹
    results_file = output_dir / f"experiment_1_results_{results['timestamp']}.json"
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    # ä¿å­˜è®­ç»ƒæ›²çº¿
    plt.figure(figsize=(10, 6))
    plt.plot(train_losses)
    plt.axhline(y=convergence_threshold, color='r', linestyle='--', label=f'Convergence threshold: {convergence_threshold}')
    plt.xlabel('Step')
    plt.ylabel('Distillation Loss')
    plt.title('å®éªŒ#1: ä¸€æ­¥Energy Headè®­ç»ƒæ›²çº¿')
    plt.legend()
    plt.grid(True)
    plt.savefig(output_dir / f'training_curve_{results["timestamp"]}.png')
    plt.close()
    
    print(f"\nğŸ“ Results saved: {results_file}")
    print(f"ğŸ‰ å®éªŒ#1 å®Œæˆï¼çŠ¶æ€: {status}")
    
    return results

def main():
    parser = argparse.ArgumentParser(description='å®éªŒ#1: ä¸€æ­¥æ‰©æ•£ Energy-Head æ¢ç´¢')
    parser.add_argument('--teacher_steps', type=int, default=500,
                       help='Teacher pre-training steps')
    parser.add_argument('--distill_steps', type=int, default=2000,
                       help='Student distillation steps')
    parser.add_argument('--batch_size', type=int, default=8,
                       help='Batch size for training')
    parser.add_argument('--learning_rate', type=float, default=2e-4,
                       help='Learning rate for student')
    parser.add_argument('--loss_type', type=str, default='mse',
                       choices=['mse', 'l1', 'huber'],
                       help='Distillation loss type')
    parser.add_argument('--output_dir', type=str, default='results/experiment_1_energy',
                       help='Output directory')
    
    args = parser.parse_args()
    
    # è¿è¡Œå®éªŒ#1
    results = run_experiment_1(args)
    
    return results

if __name__ == "__main__":
    main()