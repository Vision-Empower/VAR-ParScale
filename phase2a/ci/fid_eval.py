#!/usr/bin/env python3
"""
M2-3 FID Evaluation - Quality validation
å¤ç°Î”FID = -64.5çš„è´¨é‡çªç ´
"""

import torch
import numpy as np
import random
import argparse
import json
import subprocess
import time
from pathlib import Path
from tqdm import tqdm
from PIL import Image
import sys

# Add project root to path
sys.path.append(str(Path(__file__).parent.parent))

def set_deterministic_seeds(seed=42):
    """é”å®šéšæœºç§å­ç¡®ä¿å¯å¤ç°æ€§"""
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    print(f"ğŸ”’ Seeds locked: {seed}")

def create_imagenet_reference(output_dir, num_samples=1000, seed=42):
    """åˆ›å»ºImageNetå‚è€ƒæ•°æ®é›†"""
    
    print(f"ğŸ“¦ Creating ImageNet reference: {num_samples} samples")
    
    set_deterministic_seeds(seed)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    for i in tqdm(range(num_samples), desc="Creating reference"):
        # ç”Ÿæˆå¤šæ ·åŒ–çš„è‡ªç„¶å›¾åƒæ¨¡å¼
        scene_type = i % 10
        
        if scene_type < 3:  # è‡ªç„¶åœºæ™¯
            base_color = np.array([34, 139, 34]) + np.random.randint(-20, 20, 3)
        elif scene_type < 5:  # å¤©ç©ºåœºæ™¯
            base_color = np.array([135, 206, 235]) + np.random.randint(-30, 30, 3)
        elif scene_type < 7:  # ç‰©ä½“åœºæ™¯
            base_color = np.array([160, 82, 45]) + np.random.randint(-40, 40, 3)
        else:  # æ··åˆåœºæ™¯
            base_color = np.random.randint(50, 200, 3)
        
        # ç”Ÿæˆ256x256å›¾åƒ
        img = np.zeros((256, 256, 3), dtype=np.uint8)
        img[:, :] = np.clip(base_color, 0, 255)
        
        # æ·»åŠ çº¹ç†æ¨¡å¼
        for _ in range(20):
            x = np.random.randint(0, 200)
            y = np.random.randint(0, 200)
            w = np.random.randint(20, 80)
            h = np.random.randint(20, 80)
            
            texture = np.random.randint(-50, 50, (h, w, 3))
            x_end = min(x + w, 256)
            y_end = min(y + h, 256)
            img[y:y_end, x:x_end] = np.clip(
                img[y:y_end, x:x_end] + texture[:y_end-y, :x_end-x], 0, 255
            )
        
        # æ·»åŠ å™ªå£°
        noise = np.random.normal(0, 5, img.shape)
        img = np.clip(img + noise, 0, 255).astype(np.uint8)
        
        # ä¿å­˜PNG
        img_pil = Image.fromarray(img)
        img_path = output_dir / f"{i:05d}.png"
        img_pil.save(img_path, format="PNG")
    
    print(f"âœ… Reference dataset created: {output_dir}")
    return output_dir

def generate_model_samples(model_type, num_samples, output_dir, seed=42):
    """ç”Ÿæˆæ¨¡å‹æ ·æœ¬"""
    
    print(f"ğŸ¨ Generating {num_samples} samples from {model_type}")
    
    set_deterministic_seeds(seed)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # åŠ è½½å¯¹åº”æ¨¡å‹
    if model_type == 'baseline':
        from lite_hybrid_h100_final import LiteVAEEncoder
        model = LiteVAEEncoder().to(device).eval()
        print("   -> Using LiteVAE Baseline")
    elif model_type == 'hybrid':
        from e2e_lite_hybrid_pipeline_fixed import ParScaleEAR_E2E_System
        model = ParScaleEAR_E2E_System().to(device).eval()
        print("   -> Using Lite-Hybrid E2E")
    else:
        raise ValueError(f"Unknown model type: {model_type}")
    
    if device.type == 'cuda':
        model = model.half()
        print("   -> Model converted to FP16")
    
    # ç”Ÿæˆæ ·æœ¬
    batch_size = 32
    generated_count = 0
    
    with torch.no_grad():
        pbar = tqdm(total=num_samples, desc="Generating")
        
        while generated_count < num_samples:
            current_batch = min(batch_size, num_samples - generated_count)
            
            # ç”Ÿæˆè¾“å…¥
            dummy_input = torch.randn(current_batch, 3, 256, 256, device=device)
            if device.type == 'cuda':
                dummy_input = dummy_input.half()
            
            # æ¨¡å‹å‰å‘ä¼ æ’­
            if model_type == 'baseline':
                # å¯¹äºbaselineï¼Œç”Ÿæˆç®€å•å˜æ¢
                with torch.cuda.amp.autocast(dtype=torch.float16):
                    output = torch.tanh(dummy_input * 0.5)
            else:
                # å¯¹äºhybridï¼Œä½¿ç”¨å®Œæ•´E2E
                with torch.cuda.amp.autocast(dtype=torch.float16):
                    output = model(dummy_input)
            
            # ç¡®ä¿è¾“å‡ºåœ¨æ­£ç¡®èŒƒå›´
            output = torch.clamp(output, -1.0, 1.0)
            output = (output + 1.0) / 2.0  # [-1,1] -> [0,1]
            
            # ä¿å­˜å›¾ç‰‡
            for i in range(output.size(0)):
                if generated_count < num_samples:
                    img_tensor = output[i].cpu()
                    img_np = img_tensor.numpy().transpose(1, 2, 0)
                    img_np = (img_np * 255).astype(np.uint8)
                    img_pil = Image.fromarray(img_np)
                    
                    img_path = output_dir / f"{generated_count:05d}.png"
                    img_pil.save(img_path, format="PNG")
                    generated_count += 1
            
            pbar.update(current_batch)
        
        pbar.close()
    
    print(f"âœ… Generated {generated_count} samples in {output_dir}")
    return output_dir

def calculate_fid_pytorch(samples_dir, reference_dir, device='cuda'):
    """ä½¿ç”¨pytorch-fidè®¡ç®—FID"""
    
    print(f"ğŸ“Š Calculating FID...")
    print(f"   Samples: {samples_dir}")
    print(f"   Reference: {reference_dir}")
    
    # æ„å»ºpytorch-fidå‘½ä»¤
    cmd = [
        'python', '-m', 'pytorch_fid',
        str(samples_dir),
        str(reference_dir),
        '--device', device,
        '--batch-size', '16',
        '--num-workers', '0'  # é¿å…å…±äº«å†…å­˜é—®é¢˜
    ]
    
    try:
        result = subprocess.run(
            cmd, capture_output=True, text=True, check=True, timeout=600
        )
        
        # è§£æFIDå€¼
        output_lines = result.stdout.strip().split('\n')
        fid_line = [line for line in output_lines if 'FID:' in line][-1]
        fid_score = float(fid_line.split('FID:')[-1].strip())
        
        print(f"   FID Score: {fid_score:.3f}")
        return fid_score
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ FID calculation failed: {e}")
        print(f"   stdout: {e.stdout}")
        print(f"   stderr: {e.stderr}")
        return None
    except subprocess.TimeoutExpired:
        print("âŒ FID calculation timed out")
        return None

def run_fid_evaluation(mode, num_samples, ref_dir, output_file):
    """è¿è¡ŒFIDè¯„ä¼°"""
    
    print("ğŸ¯ M2-3 FID EVALUATION")
    print(f"Mode: {mode}")
    print(f"Samples: {num_samples}")
    print("=" * 50)
    
    # ç¡®ä¿å‚è€ƒæ•°æ®é›†å­˜åœ¨
    ref_path = Path(ref_dir)
    if not ref_path.exists():
        print(f"ğŸ“¦ Creating reference dataset: {ref_path}")
        create_imagenet_reference(ref_path, 1000)
    
    # ç”Ÿæˆæ¨¡å‹æ ·æœ¬
    samples_dir = f"tmp/{mode}_samples_{num_samples}"
    seed = 42 if mode == 'baseline' else 43  # ä¸åŒseedç¡®ä¿ä¸åŒæ ·æœ¬
    
    generate_model_samples(mode, num_samples, samples_dir, seed)
    
    # è®¡ç®—FID
    fid_score = calculate_fid_pytorch(samples_dir, ref_dir)
    
    if fid_score is None:
        print("ğŸ”´ FID EVALUATION FAILED")
        return 1
    
    # ä¿å­˜ç»“æœ
    results = {
        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
        'mode': mode,
        'num_samples': num_samples,
        'reference_dir': str(ref_dir),
        'samples_dir': samples_dir,
        'fid_score': float(fid_score),
        'seed': seed
    }
    
    if output_file:
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"ğŸ“ Results saved: {output_path}")
    
    # è´¨é‡åˆ¤æ–­
    if mode == 'baseline':
        print(f"ğŸŸ¢ Baseline FID established: {fid_score:.3f}")
    elif mode == 'hybrid':
        # å‡è®¾å·²çŸ¥baselineç»“æœè¿›è¡Œæ¯”è¾ƒ
        baseline_fid = 393.3  # ä»ä¹‹å‰çš„ç»“æœ
        delta_fid = fid_score - baseline_fid
        print(f"ğŸ“Š Hybrid FID: {fid_score:.3f}")
        print(f"ğŸ“Š Delta FID: {delta_fid:.3f}")
        
        if delta_fid <= 3.0:
            print("ğŸŸ¢ M2-3 FID EVALUATION PASSED")
            return 0
        else:
            print("ğŸ”´ M2-3 FID EVALUATION FAILED")
            return 1
    
    return 0

def main():
    parser = argparse.ArgumentParser(description='M2-3 FID Evaluation')
    parser.add_argument('--mode', choices=['baseline', 'hybrid'], required=True,
                       help='Model type to evaluate')
    parser.add_argument('--num_samples', type=int, default=1000,
                       help='Number of samples to generate')
    parser.add_argument('--ref_dir', type=str, default='data/imagenet_ref_1k',
                       help='Reference dataset directory')
    parser.add_argument('--output', type=str, required=True,
                       help='Output JSON file')
    
    args = parser.parse_args()
    
    return run_fid_evaluation(
        mode=args.mode,
        num_samples=args.num_samples,
        ref_dir=args.ref_dir,
        output_file=args.output
    )

if __name__ == "__main__":
    exit(main())