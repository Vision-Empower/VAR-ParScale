#!/bin/bash
# æœ€å°å·¥ä½œç‰ˆæœ¬ï¼šéªŒè¯çœŸæ­£çš„æ‰¹å¤„ç†æ¦‚å¿µ
set -e

SSH_CMD="ssh -p 11292 root@inst-gw.cloudexe.tech"
echo "ğŸš€ æœ€å°å·¥ä½œç‰ˆæœ¬ï¼šéªŒè¯çœŸæ­£çš„æ‰¹å¤„ç†æ¦‚å¿µ"
echo "="*60

$SSH_CMD << 'EOF'
cd /root/VAR

# åˆ›å»ºæœ€å°å·¥ä½œç‰ˆæœ¬ï¼Œè¯æ˜çœŸæ­£çš„æ‰¹å¤„ç†æ¦‚å¿µ
cat > minimal_working_test.py << 'SCRIPT_EOF'
import torch, time, os, sys, torch.nn.functional as F
os.chdir("/root/VAR"); sys.path.append("/root/VAR")
from models import build_vae_var

# ---------- build models ----------
dev = "cuda"
vae, var = build_vae_var(V=4096,Cvae=32,ch=160,share_quant_resi=4,
                         device=dev,patch_nums=(1,2,3,4,5,6,8,10,13,16),
                         num_classes=1000,depth=16,shared_aln=False)
vae.cuda().eval(); var.cuda().eval()

print("âœ… VAR model loaded successfully")

# ---------- æµ‹è¯•VARåŸç”Ÿæ‰¹å¤„ç†èƒ½åŠ› ----------
@torch.no_grad()
def test_var_native_batch(P):
    """æµ‹è¯•VARæ˜¯å¦åŸç”Ÿæ”¯æŒæ‰¹å¤„ç†"""
    print(f"\nğŸ§ª Testing VAR native batch capability with P={P}")
    
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()
    
    start_time = time.time()
    
    try:
        # å°è¯•ç›´æ¥ç”¨Pä½œä¸ºbatch sizeè°ƒç”¨VAR
        print(f"ğŸ“ Calling autoregressive_infer_cfg with B={P}")
        outputs = var.autoregressive_infer_cfg(
            B=P, label_B=None, cfg=1.0, top_p=0.95, top_k=900
        )
        success = True
        print(f"âœ… Success! Output shape: {outputs.shape}")
        
    except Exception as e:
        print(f"âŒ Native batch failed: {e}")
        print(f"ğŸ”„ Falling back to sequential calls...")
        
        # å›é€€åˆ°é¡ºåºè°ƒç”¨
        outputs = []
        for i in range(P):
            out = var.autoregressive_infer_cfg(
                B=1, label_B=None, cfg=1.0, 
                top_p=max(0.85, 0.95-i*0.02), 
                top_k=max(600, 900-i*50)
            )
            outputs.append(out)
        success = False
    
    torch.cuda.synchronize()
    
    latency = (time.time() - start_time) * 1000
    peak_mem = torch.cuda.max_memory_allocated() / 1e9
    
    # åˆ†æè¾“å‡º
    if success:
        print(f"ğŸ“Š Native batch output shape: {outputs.shape}")
        if outputs.dim() >= 1 and outputs.size(0) == P:
            print(f"âœ… Successfully generated {P} samples in single call")
            
            # è®¡ç®—diversity
            diversity = 0.0
            if P > 1:
                similarities = []
                for i in range(P):
                    for j in range(i + 1, P):
                        # å®‰å…¨çš„similarityè®¡ç®—
                        try:
                            sim = F.cosine_similarity(
                                outputs[i].flatten().float(), 
                                outputs[j].flatten().float(), 
                                dim=0
                            ).item()
                            similarities.append(abs(sim))
                        except:
                            similarities.append(1.0)  # å‡è®¾ç›¸ä¼¼
                
                if similarities:
                    diversity = 1.0 - (sum(similarities) / len(similarities))
            
            print(f"ğŸ¨ Diversity between samples: {diversity:.3f}")
        else:
            print(f"âš ï¸ Unexpected output shape for batch size {P}")
            diversity = 0.0
    else:
        print(f"ğŸ“Š Sequential outputs: {len(outputs)} samples")
        if len(outputs) > 1:
            # è®¡ç®—diversity for sequential outputs
            similarities = []
            for i in range(len(outputs)):
                for j in range(i + 1, len(outputs)):
                    try:
                        sim = F.cosine_similarity(
                            outputs[i].flatten().float(), 
                            outputs[j].flatten().float(), 
                            dim=0
                        ).item()
                        similarities.append(abs(sim))
                    except:
                        similarities.append(1.0)
            
            diversity = 1.0 - (sum(similarities) / len(similarities)) if similarities else 0.0
        else:
            diversity = 0.0
    
    implementation = "native_batch" if success else "sequential"
    print(f"P={P:<2}  Lat {latency:>6.1f}ms  PeakMem {peak_mem:.2f}GB  Diversity {diversity:.3f}  ({implementation})")
    
    return {
        'latency': latency,
        'peak_mem': peak_mem, 
        'diversity': diversity,
        'implementation': implementation,
        'success': success
    }

# ---------- è¿è¡Œæµ‹è¯•å¹¶åˆ†æ ----------
print("ğŸš€ Running comprehensive VAR batch tests...")
print("="*60)

results = {}
for P in (1, 2, 4):
    results[P] = test_var_native_batch(P)

print(f"\nğŸ“Š FINAL ANALYSIS")
print("="*30)

baseline = results[1]
print(f"Baseline (P=1): {baseline['latency']:.1f}ms, {baseline['peak_mem']:.2f}GB")

for P in (2, 4):
    result = results[P]
    
    # è®¡ç®—æ•ˆç‡
    expected_latency = baseline['latency'] * P  # å¦‚æœæ˜¯é¡ºåºæ‰§è¡Œçš„æœŸæœ›å»¶è¿Ÿ
    efficiency = expected_latency / result['latency'] if result['latency'] > 0 else 0
    
    # å†…å­˜æ¯”ä¾‹
    mem_ratio = result['peak_mem'] / baseline['peak_mem']
    
    print(f"P={P}: {result['latency']:.1f}ms, {result['peak_mem']:.2f}GB")
    print(f"  Efficiency: {efficiency:.1%} (expect â‰¤100% for true batching)")
    print(f"  Memory ratio: {mem_ratio:.2f}x (expect >1.5x for P=2, >2.5x for P=4)")
    print(f"  Implementation: {result['implementation']}")
    print(f"  Diversity: {result['diversity']:.3f}")
    
    # åˆ¤æ–­æ˜¯å¦ä¸ºçœŸæ­£çš„æ‰¹å¤„ç†
    if result['implementation'] == 'native_batch':
        if efficiency <= 1.0 and mem_ratio >= 1.5:
            print(f"  âœ… TRUE BATCHING DETECTED!")
        elif efficiency > 1.5:
            print(f"  ğŸš¨ SUSPICIOUS: Super-linear efficiency!")
        else:
            print(f"  âš ï¸ Partial batching or other effects")
    else:
        print(f"  ğŸ“ Sequential implementation (baseline)")
    print()

print("ğŸ¯ Summary: Looking for native_batch + efficiency â‰¤100% + memory scaling")
SCRIPT_EOF

echo "ğŸš€ æ‰§è¡Œæœ€å°å·¥ä½œç‰ˆæœ¬æµ‹è¯•..."
python3 minimal_working_test.py
EOF

echo "âœ… æœ€å°å·¥ä½œç‰ˆæœ¬æµ‹è¯•æ‰§è¡Œå®Œæˆ!"