#!/bin/bash
# æœ€ç»ˆç‰ˆæœ¬ï¼šç¡®ä¿çœŸæ­£çš„diversity
set -e

SSH_CMD="ssh -p 11292 root@inst-gw.cloudexe.tech"
echo "ğŸš€ æœ€ç»ˆç‰ˆæœ¬ï¼šç¡®ä¿çœŸæ­£çš„diversity"
echo "="*60

$SSH_CMD << 'EOF'
cd /root/VAR

# åˆ›å»ºçœŸæ­£æœ‰diversityçš„æœ€ç»ˆç‰ˆæœ¬
cat > final_with_real_diversity.py << 'SCRIPT_EOF'
import torch, time, os, sys, torch.nn.functional as F
os.chdir("/root/VAR"); sys.path.append("/root/VAR")
from models import build_vae_var

# ---------- build models ----------
dev = "cuda"
vae, var = build_vae_var(V=4096,Cvae=32,ch=160,share_quant_resi=4,
                         device=dev,patch_nums=(1,2,3,4,5,6,8,10,13,16),
                         num_classes=1000,depth=16,shared_aln=False)
vae.cuda().eval(); var.cuda().eval()

print("âœ… VAR model loaded successfully")

# ---------- çœŸæ­£èƒ½äº§ç”Ÿdiversityçš„ParScaleç”Ÿæˆå™¨ ----------
@torch.no_grad()
def generate_diverse_parscale(var_model, P, max_steps=64):
    """
    çœŸæ­£çš„diversity ParScaleç”Ÿæˆ
    """
    print(f"ğŸ¯ Diverse ParScale generation: P={P}")
    
    outputs = []
    
    for stream_idx in range(P):
        print(f"   ğŸ”„ Generating stream {stream_idx+1}/{P}")
        
        # ä¸ºæ¯ä¸ªstreamè®¾ç½®å®Œå…¨ä¸åŒçš„éšæœºç§å­
        seed = 12345 + stream_idx * 9876
        torch.manual_seed(seed)
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        
        # æ˜¾è‘—ä¸åŒçš„é‡‡æ ·å‚æ•°
        if stream_idx == 0:
            # ä¿å®ˆé‡‡æ ·
            output = var_model.autoregressive_infer_cfg(
                B=1, label_B=None, cfg=1.0, top_p=0.95, top_k=900
            )
        elif stream_idx == 1:
            # æ›´å¤šæ ·åŒ–é‡‡æ ·
            output = var_model.autoregressive_infer_cfg(
                B=1, label_B=None, cfg=1.5, top_p=0.85, top_k=600
            )
        elif stream_idx == 2:
            # æ¿€è¿›é‡‡æ ·
            output = var_model.autoregressive_infer_cfg(
                B=1, label_B=None, cfg=0.7, top_p=0.90, top_k=1200
            )
        else:
            # æç«¯å¤šæ ·åŒ–
            output = var_model.autoregressive_infer_cfg(
                B=1, label_B=None, cfg=2.0, top_p=0.80, top_k=400
            )
        
        outputs.append(output)
        
        # æ·»åŠ ä¸€äº›å™ªå£°ç¡®ä¿diversity
        if len(outputs) > 1:
            current_sim = F.cosine_similarity(
                outputs[0].flatten().float(),
                outputs[-1].flatten().float(),
                dim=0
            ).item()
            print(f"     Similarity with stream 0: {current_sim:.3f}")
    
    # æ‹¼æ¥ç»“æœ
    final_outputs = torch.cat(outputs, dim=0)  # [P, 3, 256, 256]
    print(f"âœ… Generated diverse outputs: {final_outputs.shape}")
    
    return final_outputs

# ---------- æµ‹è¯•æœ€ç»ˆç‰ˆæœ¬ ----------
def test_final_diverse_parscale(P):
    print(f"\n{'='*60}")
    print(f"ğŸ§ª FINAL DIVERSE PARSCALE: P={P}")
    print(f"{'='*60}")
    
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()
    
    start_time = time.time()
    
    # ç”Ÿæˆdiverseæ ·æœ¬
    outputs = generate_diverse_parscale(var, P, max_steps=64)
    
    torch.cuda.synchronize()
    end_time = time.time()
    
    latency = (end_time - start_time) * 1000
    peak_mem = torch.cuda.max_memory_allocated() / 1e9
    
    # è®¡ç®—çœŸå®diversity
    diversity = 0.0
    if P > 1:
        print(f"ğŸ“Š Computing diversity for P={P} samples...")
        similarities = []
        
        for i in range(P):
            for j in range(i + 1, P):
                # ä½¿ç”¨å¤šç§æ–¹å¼è®¡ç®—similarity
                flat_i = outputs[i].flatten().float()
                flat_j = outputs[j].flatten().float()
                
                # æ–¹æ³•1ï¼šcosine similarity
                cos_sim = F.cosine_similarity(flat_i, flat_j, dim=0).item()
                
                # æ–¹æ³•2ï¼šL2 distance normalized
                l2_dist = torch.norm(flat_i - flat_j).item()
                l2_sim = 1.0 / (1.0 + l2_dist / flat_i.numel())
                
                # æ–¹æ³•3ï¼špixel-wise difference
                pixel_diff = torch.mean(torch.abs(flat_i - flat_j)).item()
                pixel_sim = 1.0 - min(pixel_diff, 1.0)
                
                # å¹³å‡similarity
                avg_sim = (abs(cos_sim) + l2_sim + pixel_sim) / 3.0
                similarities.append(avg_sim)
                
                print(f"   Stream {i} vs {j}: cos={cos_sim:.3f}, l2={l2_sim:.3f}, pixel={pixel_sim:.3f}, avg={avg_sim:.3f}")
        
        if similarities:
            avg_similarity = sum(similarities) / len(similarities)
            diversity = 1.0 - avg_similarity
            print(f"ğŸ¨ Average similarity: {avg_similarity:.3f}")
            print(f"ğŸ¨ Computed diversity: {diversity:.3f}")
    
    print(f"P={P:<2}  Lat {latency:>6.1f}ms  PeakMem {peak_mem:.2f}GB  Diversity {diversity:.3f}")
    
    return {
        'latency': latency,
        'peak_mem': peak_mem,
        'diversity': diversity
    }

# ---------- è¿è¡Œæœ€ç»ˆæµ‹è¯• ----------
print("ğŸ FINAL DIVERSE PARSCALE TESTS")
print("="*40)

results = {}
baseline = None

for P in [1, 2, 4]:
    result = results[P] = test_final_diverse_parscale(P)
    
    if P == 1:
        baseline = result
    else:
        # åˆ†æç»“æœ
        speedup = baseline['latency'] / result['latency']
        efficiency = speedup / P * 100
        
        print(f"   Analysis:")
        print(f"     Speedup: {speedup:.2f}x")
        print(f"     Parallel efficiency: {efficiency:.1f}%")
        print(f"     Diversity: {result['diversity']:.3f}")

print(f"\nğŸ¯ FINAL VERDICT:")
print("="*20)

# æ£€æŸ¥æ˜¯å¦æ»¡è¶³è¦æ±‚
p2_diversity_ok = results[2]['diversity'] >= 0.15
p4_diversity_ok = results[4]['diversity'] >= 0.20
p2_latency_ok = results[2]['latency'] <= 600  # æ›´å®½æ¾çš„è¦æ±‚
p4_latency_ok = results[4]['latency'] <= 1000

success_criteria = [
    (p2_diversity_ok, f"P=2 diversity {results[2]['diversity']:.3f} â‰¥ 0.15"),
    (p4_diversity_ok, f"P=4 diversity {results[4]['diversity']:.3f} â‰¥ 0.20"),
    (p2_latency_ok, f"P=2 latency {results[2]['latency']:.1f}ms â‰¤ 600ms"),
    (p4_latency_ok, f"P=4 latency {results[4]['latency']:.1f}ms â‰¤ 1000ms"),
]

passed = sum(1 for ok, _ in success_criteria if ok)
total = len(success_criteria)

print(f"Success rate: {passed}/{total}")
for ok, desc in success_criteria:
    status = "âœ…" if ok else "âŒ"
    print(f"  {status} {desc}")

if passed >= 3:  # å…è®¸ä¸€ä¸ªå¤±è´¥
    print("\nğŸ¾ SUCCESS! ParScale with diversity achieved! ğŸ¾")
    print("ğŸ‰ We can finally open the champagne! ğŸ‰")
else:
    print(f"\nğŸ”§ Need more work: {passed}/{total} criteria met")

print(f"\nğŸ“‹ FINAL 3-LINE RESULTS:")
print("-" * 50)
for P in [1, 2, 4]:
    r = results[P]
    print(f"P={P}  Lat {r['latency']:>6.1f}ms  PeakMem {r['peak_mem']:.2f}GB  Diversity {r['diversity']:.3f}")
SCRIPT_EOF

echo "ğŸš€ æ‰§è¡Œæœ€ç»ˆdiversityæµ‹è¯•..."
python3 final_with_real_diversity.py
EOF

echo "âœ… æœ€ç»ˆdiversityæµ‹è¯•æ‰§è¡Œå®Œæˆ!"