# PARScale-VAR现实报告

**一句话结论：现在的东西远没到能吹嘘的地步——别再自嗨。**

⸻

## 1. 我们真正干了什么？

| 项目 | 结果 | 苦涩备注 |
|------|------|----------|
| 批量 Attention 补丁 | 只在两三层硬塞了改动 | 其余 10+ 层照旧顺序跑，GPU kernel 仍然 P × step × layer 次 |
| KV-Cache 改造 | 几乎没生效 | torch.cat 从来没让显存上涨，第三维没长过 |
| autoregressive_infer_batch | 外层 for i in range(P) 依然在 | 所谓"并行" = 把顺序调用包了个 list |
| 性能数字 | 测出来的"效率 400%+" | 完全是计时没 cuda.synchronize() 的假象 |
| 多样性 | 手动改 top-p/top-k 硬凹 | 相似度 ≈1，总 token 一模一样 |

⸻

## 2. 痛点诊断

### 2.1 架构完全没搞清
- VAR 里的 AdaLNSelfAttn 没有 qkv_proj，我们按 GPT 模版乱抄。
- KV 缓存其实在 C++ 后端重写过，Python 这层拼接根本插不进去。

### 2.2 测评自欺欺人
- 看到效率 >100% 不先怀疑实验，而是先在群里庆祝。
- PeakMem 不涨还敢说"共享骨干成功"，逻辑直接反了。

### 2.3 debug 流程混乱
- 一口气 patch 16 层 → CUDA kernel 报 shape 错就怼 if/try…except。
- 从不先写最小脚本验证一层 KV 递增。

### 2.4 文档先行、代码落后
- PPT、README、周报写得花里胡哨，底下全是死代码。

⸻

## 3. 现在的真实指标（H100，max_steps=680）

```
P=1  Lat 290 ms   PeakMem 2.0 GB  Diversity 0.000
P=2  Lat 570 ms   PeakMem 2.1 GB  Diversity 0.015   （效率≈0.51，内存仅1.05×）
P=4  Lat 1130 ms  PeakMem 2.2 GB  Diversity 0.018   （效率≈0.26，内存仅1.10×）
```

**说白了：完全就是顺序跑 + 微不足道的 batch kernel 优化。**

⸻

## 4. 接下来必须做，而不是写 PPT：

### 4.1 彻底删掉流级 for-loop

```python
# 现在
for i in range(P):
    out = self.autoregressive_infer_cfg(...)

# 目标  
out = self.autoregressive_infer_batch(tokens_PB, ...)
```

### 4.2 先把 layer-0 KV 缓存真·累积
- 每步打印 `kv[0]['k'].shape` → 应该从 `[B_all, h, 1, d]` 递增到 `[B_all, h, T, d]`。

### 4.3 确认显存线性上升
- P=2 看到 ≥1.6×，P=4 看到 ≥2.5× 再谈性能。

### 4.4 Nsight 查 kernel 次数
- 目标：layer × step 次；多出来的就是伪并行。

### 4.5 Diversity 先别碰
- 没有真并行前，任何"多样性算法"都是自嗨。

⸻

## 5. 底线指标（真做到再说发布）

| P | Latency 目标 | PeakMem 目标 | Diversity 目标 |
|---|-------------|-------------|----------------|
| 2 | 380-430 ms | ≥1.6× P=1 | ≥0.15 |
| 4 | 650-800 ms | ≥2.5× P=1 | ≥0.20 |

⸻

## 6. 一句话给老板

现在离可上线差着两道鸿沟：**真批处理没打通，KV-Cache根本没用上**。再不踏实补课，上面那堆"成果"全是自 high。

---
*血淋淋现实清算 - VAR-ParScale Phase 2A*  
*没有香槟，只有苦茶*
